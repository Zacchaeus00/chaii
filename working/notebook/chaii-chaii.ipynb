{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81723007",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-13T07:44:41.916488Z",
     "iopub.status.busy": "2021-08-13T07:44:41.915968Z",
     "iopub.status.idle": "2021-08-13T07:44:51.370198Z",
     "shell.execute_reply": "2021-08-13T07:44:51.369163Z",
     "shell.execute_reply.started": "2021-08-13T07:25:30.332319Z"
    },
    "papermill": {
     "duration": 9.479205,
     "end_time": "2021-08-13T07:44:51.370351",
     "exception": false,
     "start_time": "2021-08-13T07:44:41.891146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-cloud 0.1.13 requires tensorflow<3.0,>=1.15.0, which is not installed.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda112, which is not installed.\r\n",
      "cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda110, which is not installed.\r\n",
      "s3fs 2021.6.1 requires fsspec==2021.06.1, but you have fsspec 2021.6.0 which is incompatible.\r\n",
      "pytorch-lightning 1.3.8 requires fsspec[http]!=2021.06.0,>=2021.05.0, but you have fsspec 2021.6.0 which is incompatible.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires dask<=2021.5.1,>=2021.4.0, but you have dask 2021.6.2 which is incompatible.\r\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires distributed<=2021.5.1,>=2.22.0, but you have distributed 2021.6.2 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall fsspec -qq -y\n",
    "!pip install --no-index --find-links ../input/hf-datasets/wheels datasets -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1e22e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:44:51.401121Z",
     "iopub.status.busy": "2021-08-13T07:44:51.399851Z",
     "iopub.status.idle": "2021-08-13T07:44:51.402641Z",
     "shell.execute_reply": "2021-08-13T07:44:51.402253Z",
     "shell.execute_reply.started": "2021-08-13T07:28:47.967836Z"
    },
    "papermill": {
     "duration": 0.019784,
     "end_time": "2021-08-13T07:44:51.402768",
     "exception": false,
     "start_time": "2021-08-13T07:44:51.382984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/tez-lib/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4684f93e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:44:51.436759Z",
     "iopub.status.busy": "2021-08-13T07:44:51.435987Z",
     "iopub.status.idle": "2021-08-13T07:44:57.376106Z",
     "shell.execute_reply": "2021-08-13T07:44:57.375227Z",
     "shell.execute_reply.started": "2021-08-13T07:30:06.556260Z"
    },
    "papermill": {
     "duration": 5.961245,
     "end_time": "2021-08-13T07:44:57.376248",
     "exception": false,
     "start_time": "2021-08-13T07:44:51.415003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tez\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "\n",
    "class ChaiiModel(tez.Model):\n",
    "    def __init__(self, model_name, num_train_steps, steps_per_epoch, learning_rate):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.model_name = model_name\n",
    "        self.num_train_steps = num_train_steps\n",
    "        self.step_scheduler_after = \"batch\"\n",
    "\n",
    "        hidden_dropout_prob: float = 0.0\n",
    "        layer_norm_eps: float = 1e-7\n",
    "\n",
    "        config = transformers.AutoConfig.from_pretrained(model_name)\n",
    "        config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"layer_norm_eps\": layer_norm_eps,\n",
    "                \"add_pooling_layer\": False,\n",
    "            }\n",
    "        )\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(model_name, config=config)\n",
    "        self.output = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids=None, start_positions=None, end_positions=None):\n",
    "        transformer_out = self.transformer(ids, mask)\n",
    "        sequence_output = transformer_out[0]\n",
    "        logits = self.output(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits = end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "        return (start_logits, end_logits), 0, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f939cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:44:57.405563Z",
     "iopub.status.busy": "2021-08-13T07:44:57.404778Z",
     "iopub.status.idle": "2021-08-13T07:44:57.718708Z",
     "shell.execute_reply": "2021-08-13T07:44:57.718264Z",
     "shell.execute_reply.started": "2021-08-13T07:30:06.933471Z"
    },
    "papermill": {
     "duration": 0.330328,
     "end_time": "2021-08-13T07:44:57.718859",
     "exception": false,
     "start_time": "2021-08-13T07:44:57.388531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0eb219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:44:57.749093Z",
     "iopub.status.busy": "2021-08-13T07:44:57.748344Z",
     "iopub.status.idle": "2021-08-13T07:44:57.752009Z",
     "shell.execute_reply": "2021-08-13T07:44:57.751595Z",
     "shell.execute_reply.started": "2021-08-13T07:42:39.069852Z"
    },
    "papermill": {
     "duration": 0.020593,
     "end_time": "2021-08-13T07:44:57.752118",
     "exception": false,
     "start_time": "2021-08-13T07:44:57.731525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChaiiDataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            \"ids\": torch.tensor(self.data[item][\"input_ids\"], dtype=torch.long),\n",
    "            \"mask\": torch.tensor(self.data[item][\"attention_mask\"], dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8ab8cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:44:57.783780Z",
     "iopub.status.busy": "2021-08-13T07:44:57.783246Z",
     "iopub.status.idle": "2021-08-13T07:44:57.786911Z",
     "shell.execute_reply": "2021-08-13T07:44:57.786512Z",
     "shell.execute_reply.started": "2021-08-13T07:30:08.445333Z"
    },
    "papermill": {
     "duration": 0.022844,
     "end_time": "2021-08-13T07:44:57.787016",
     "exception": false,
     "start_time": "2021-08-13T07:44:57.764172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples, tokenizer, pad_on_right, max_length, doc_stride):\n",
    "    # ref: https://github.com/huggingface/notebooks/blob/master/examples/question_answering.ipynb\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
    "        # position is part of the context or not.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d04ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:44:57.825773Z",
     "iopub.status.busy": "2021-08-13T07:44:57.824534Z",
     "iopub.status.idle": "2021-08-13T07:44:57.826806Z",
     "shell.execute_reply": "2021-08-13T07:44:57.827251Z",
     "shell.execute_reply.started": "2021-08-13T07:30:09.462640Z"
    },
    "papermill": {
     "duration": 0.028312,
     "end_time": "2021-08-13T07:44:57.827373",
     "exception": false,
     "start_time": "2021-08-13T07:44:57.799061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocess_qa_predictions(\n",
    "    examples, tokenizer, features, raw_predictions, n_best_size=20, max_answer_length=30, squad_v2=False\n",
    "):\n",
    "    # ref: https://github.com/huggingface/notebooks/blob/master/examples/question_answering.ipynb\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    # Build a map example to its corresponding features.\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    # The dictionaries we have to fill.\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    # Logging.\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    # Let's loop over all the examples!\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        # Those are the indices of the features associated to the current example.\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None  # Only used if squad_v2 is True.\n",
    "        valid_answers = []\n",
    "\n",
    "        context = example[\"context\"]\n",
    "        # Looping through all the features associated to the current example.\n",
    "        for feature_index in feature_indices:\n",
    "            # We grab the predictions of the model for this feature.\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
    "            # context.\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            # Update minimum null prediction.\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "                    # to part of the input_ids that are not in the context.\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char:end_char],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
    "            # failure.\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "\n",
    "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
    "        if not squad_v2:\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        else:\n",
    "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "            predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c51180",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:44:57.855147Z",
     "iopub.status.busy": "2021-08-13T07:44:57.854579Z",
     "iopub.status.idle": "2021-08-13T07:44:59.952983Z",
     "shell.execute_reply": "2021-08-13T07:44:59.951992Z",
     "shell.execute_reply.started": "2021-08-13T07:30:10.094474Z"
    },
    "papermill": {
     "duration": 2.113531,
     "end_time": "2021-08-13T07:44:59.953127",
     "exception": false,
     "start_time": "2021-08-13T07:44:57.839596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"../input/f0test/\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d72dbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:44:59.982225Z",
     "iopub.status.busy": "2021-08-13T07:44:59.981569Z",
     "iopub.status.idle": "2021-08-13T07:45:48.410861Z",
     "shell.execute_reply": "2021-08-13T07:45:48.409883Z",
     "shell.execute_reply.started": "2021-08-13T07:41:23.628485Z"
    },
    "papermill": {
     "duration": 48.445585,
     "end_time": "2021-08-13T07:45:48.411012",
     "exception": false,
     "start_time": "2021-08-13T07:44:59.965427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/xlmrob were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = ChaiiModel(model_name=\"../input/xlmrob\", num_train_steps=0, steps_per_epoch=0, learning_rate=0)\n",
    "model.load(\"../input/f0test/pytorch_model.bin\", weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0ce6e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:45:48.441977Z",
     "iopub.status.busy": "2021-08-13T07:45:48.441437Z",
     "iopub.status.idle": "2021-08-13T07:45:49.100320Z",
     "shell.execute_reply": "2021-08-13T07:45:49.100747Z",
     "shell.execute_reply.started": "2021-08-13T07:42:49.822558Z"
    },
    "papermill": {
     "duration": 0.677074,
     "end_time": "2021-08-13T07:45:49.100896",
     "exception": false,
     "start_time": "2021-08-13T07:45:48.423822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d3c1a30b224f2ab39493967e626829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0acf0fd5e1248d19f3d77f857638cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=67.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "max_length = 384\n",
    "doc_stride = 128\n",
    "\n",
    "test_data = pd.read_csv(\"../input/chaii-hindi-and-tamil-question-answering/test.csv\")\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "test_features = test_dataset.map(\n",
    "    partial(\n",
    "        prepare_validation_features, \n",
    "        tokenizer=tokenizer,\n",
    "        pad_on_right=pad_on_right, \n",
    "        max_length=max_length,\n",
    "        doc_stride=doc_stride\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset.column_names\n",
    ")\n",
    "test_feats_small = test_features.map(\n",
    "    lambda example: example, remove_columns=['example_id', 'offset_mapping']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d33d0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:45:49.133990Z",
     "iopub.status.busy": "2021-08-13T07:45:49.133208Z",
     "iopub.status.idle": "2021-08-13T07:45:49.145213Z",
     "shell.execute_reply": "2021-08-13T07:45:49.144824Z",
     "shell.execute_reply.started": "2021-08-13T07:42:51.335719Z"
    },
    "papermill": {
     "duration": 0.030108,
     "end_time": "2021-08-13T07:45:49.145318",
     "exception": false,
     "start_time": "2021-08-13T07:45:49.115210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    ChaiiDataset(test_feats_small), \n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "170257c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:45:49.179273Z",
     "iopub.status.busy": "2021-08-13T07:45:49.178636Z",
     "iopub.status.idle": "2021-08-13T07:45:52.927031Z",
     "shell.execute_reply": "2021-08-13T07:45:52.926490Z",
     "shell.execute_reply.started": "2021-08-13T07:43:06.746058Z"
    },
    "papermill": {
     "duration": 3.768246,
     "end_time": "2021-08-13T07:45:52.927177",
     "exception": false,
     "start_time": "2021-08-13T07:45:49.158931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_logits = []\n",
    "end_logits = []\n",
    "\n",
    "for b_idx, data in enumerate(data_loader):\n",
    "    with torch.no_grad():\n",
    "        for key, value in data.items():\n",
    "            data[key] = value.to(\"cuda\")\n",
    "        output, _, _ = model(**data)\n",
    "        start = output[0].detach().cpu().numpy()\n",
    "        end = output[1].detach().cpu().numpy()\n",
    "        start_logits.append(start)\n",
    "        end_logits.append(end)\n",
    "\n",
    "start_logits = np.vstack(start_logits)\n",
    "end_logits = np.vstack(end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "385137c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:45:53.072105Z",
     "iopub.status.busy": "2021-08-13T07:45:53.069111Z",
     "iopub.status.idle": "2021-08-13T07:45:53.316184Z",
     "shell.execute_reply": "2021-08-13T07:45:53.317121Z",
     "shell.execute_reply.started": "2021-08-13T07:43:13.949347Z"
    },
    "papermill": {
     "duration": 0.375866,
     "end_time": "2021-08-13T07:45:53.317322",
     "exception": false,
     "start_time": "2021-08-13T07:45:52.941456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:00<00:00, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 5 example predictions split into 67 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 20.87it/s]\n"
     ]
    }
   ],
   "source": [
    "fin_preds = postprocess_qa_predictions(test_dataset, tokenizer, test_features, (start_logits, end_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a9159e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:45:53.353608Z",
     "iopub.status.busy": "2021-08-13T07:45:53.353128Z",
     "iopub.status.idle": "2021-08-13T07:45:53.357115Z",
     "shell.execute_reply": "2021-08-13T07:45:53.356371Z",
     "shell.execute_reply.started": "2021-08-13T07:43:17.390549Z"
    },
    "papermill": {
     "duration": 0.022614,
     "end_time": "2021-08-13T07:45:53.357223",
     "exception": false,
     "start_time": "2021-08-13T07:45:53.334609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = []\n",
    "for p1, p2 in fin_preds.items():\n",
    "    submission.append((p1, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e4b9ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:45:53.393704Z",
     "iopub.status.busy": "2021-08-13T07:45:53.393138Z",
     "iopub.status.idle": "2021-08-13T07:45:53.399395Z",
     "shell.execute_reply": "2021-08-13T07:45:53.398650Z",
     "shell.execute_reply.started": "2021-08-13T07:43:18.942846Z"
    },
    "papermill": {
     "duration": 0.02723,
     "end_time": "2021-08-13T07:45:53.399501",
     "exception": false,
     "start_time": "2021-08-13T07:45:53.372271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = pd.DataFrame(submission, columns=[\"id\", \"PredictionString\"])\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46dd1be1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:45:53.436036Z",
     "iopub.status.busy": "2021-08-13T07:45:53.435251Z",
     "iopub.status.idle": "2021-08-13T07:45:53.449612Z",
     "shell.execute_reply": "2021-08-13T07:45:53.449079Z",
     "shell.execute_reply.started": "2021-08-13T07:43:20.671256Z"
    },
    "papermill": {
     "duration": 0.035213,
     "end_time": "2021-08-13T07:45:53.449719",
     "exception": false,
     "start_time": "2021-08-13T07:45:53.414506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22bff3dec</td>\n",
       "      <td>येलन चीन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282758170</td>\n",
       "      <td>20 अप्रैल 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d60987e0e</td>\n",
       "      <td>१२ मार्च १८२४</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f99c770dc</td>\n",
       "      <td>13,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40dec1964</td>\n",
       "      <td>ரோச்டேல் பயனீர்</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id PredictionString\n",
       "0  22bff3dec         येलन चीन\n",
       "1  282758170   20 अप्रैल 2010\n",
       "2  d60987e0e    १२ मार्च १८२४\n",
       "3  f99c770dc              13,\n",
       "4  40dec1964  ரோச்டேல் பயனீர்"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 80.560129,
   "end_time": "2021-08-13T07:45:56.282877",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-13T07:44:35.722748",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "353a0588651440d78740cbf2453c4753": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a5a55888a7b045a6879792048e2ebed7",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_93de0e90c9104fac9338371cbfa7ca70",
       "value": 1.0
      }
     },
     "4be6d47005f7478b8ca0eff6ec346b25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "53a19a44d98941e6a45d659fa021de0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "66fcc6fe4a1345bdbb7d1b5dd5ed8806": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fe00d7565a61451fb42be98d031126a3",
       "placeholder": "​",
       "style": "IPY_MODEL_53a19a44d98941e6a45d659fa021de0e",
       "value": "&lt;tqdm.auto.tqdm object at 0x7fee2b6e9210&gt;"
      }
     },
     "767c5c6e729d444093c0ae5d2ac2ed9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93de0e90c9104fac9338371cbfa7ca70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a42df24ba8354198a2cc0d5440eb3aa3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a5a55888a7b045a6879792048e2ebed7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6aae47311024e7abf2fb5370db0d0fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b07132e23545434db21608e13fb792be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_767c5c6e729d444093c0ae5d2ac2ed9b",
       "max": 67.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4be6d47005f7478b8ca0eff6ec346b25",
       "value": 67.0
      }
     },
     "b4d3c1a30b224f2ab39493967e626829": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_353a0588651440d78740cbf2453c4753",
        "IPY_MODEL_e2b07cd8cd6d4ac887d2ae14ac9eb815"
       ],
       "layout": "IPY_MODEL_cff1b334ef9547b98a31e1f65954a656"
      }
     },
     "bf262ecaceda4967ac85eb550d2ac521": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0acf0fd5e1248d19f3d77f857638cfb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b07132e23545434db21608e13fb792be",
        "IPY_MODEL_66fcc6fe4a1345bdbb7d1b5dd5ed8806"
       ],
       "layout": "IPY_MODEL_bf262ecaceda4967ac85eb550d2ac521"
      }
     },
     "cff1b334ef9547b98a31e1f65954a656": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2b07cd8cd6d4ac887d2ae14ac9eb815": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a6aae47311024e7abf2fb5370db0d0fe",
       "placeholder": "​",
       "style": "IPY_MODEL_a42df24ba8354198a2cc0d5440eb3aa3",
       "value": "&lt;tqdm.auto.tqdm object at 0x7fee2a201bd0&gt;"
      }
     },
     "fe00d7565a61451fb42be98d031126a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
