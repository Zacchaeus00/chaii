DeprecationWarning: 'source deactivate' is deprecated. Use 'conda deactivate'.
Traceback (most recent call last):
  File "finetune.py", line 127, in <module>
    tokenizer = XLMRobertaTokenizerFast.from_pretrained(model_checkpoint) if 'info' in model_checkpoint else AutoTokenizer.from_pretrained(model_checkpoint)
  File "/gpfsnyu/home/yw3642/.conda/envs/kaggle/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 431, in from_pretrained
    tokenizer_class = tokenizer_class_from_name(tokenizer_class_candidate)
  File "/gpfsnyu/home/yw3642/.conda/envs/kaggle/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 225, in tokenizer_class_from_name
    module = importlib.import_module(f".{module_name}", "transformers.models")
  File "/gpfsnyu/home/yw3642/.conda/envs/kaggle/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'transformers.models.xlm-roberta'
