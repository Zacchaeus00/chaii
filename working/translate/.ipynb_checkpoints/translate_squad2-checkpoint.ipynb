{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2c9838ab-9376-4eb3-bbd9-950fa2c58f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk.data\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from pathlib import Path\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/yuchen/kaggle/chaii/working/translate/chaii-325014-09f84f361067.json\"\n",
    "\n",
    "def retry(fun, max_tries=10):\n",
    "    for i in range(max_tries):\n",
    "        try:\n",
    "            time.sleep(0.3) \n",
    "            fun()\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "def translate_text(target, text):\n",
    "    \"\"\"Translates text into the target language.\n",
    "\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "    import six\n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(text, format_='text', source_language='en', target_language=target)\n",
    "\n",
    "#     print(u\"Text: {}\".format(result[\"input\"]))\n",
    "#     print(u\"Translation: {}\".format(result[\"translatedText\"]))\n",
    "#     print(u\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\n",
    "    return result[\"translatedText\"]\n",
    "\n",
    "def translate_texts(target, text):\n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(text, format_='text', source_language='en', target_language=target)\n",
    "\n",
    "#     print(u\"Text: {}\".format(result[\"input\"]))\n",
    "#     print(u\"Translation: {}\".format(result[\"translatedText\"]))\n",
    "#     print(u\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\n",
    "    return result\n",
    "\n",
    "def translate_text_use_cache(target, text, only_cache=False):\n",
    "    if text in translated_cache:\n",
    "        return translated_cache[text]\n",
    "    if only_cache:\n",
    "        raise KeyError\n",
    "    text_translated = translate_text(target, text)\n",
    "    translated_cache[text] = text_translated\n",
    "    return text_translated\n",
    "\n",
    "def split2sentence(paragraph):\n",
    "    slist = tokenizer.tokenize(paragraph)\n",
    "    sentence_lengths = [len(x)+1 for x in slist]\n",
    "    if np.sum(sentence_lengths)-1 != len(paragraph):\n",
    "        return None, None\n",
    "    sentence_starts = [0]\n",
    "    for sl in sentence_lengths[:-1]:\n",
    "        sentence_starts.append(sentence_starts[-1]+sl)\n",
    "    return slist, sentence_starts\n",
    "\n",
    "def get_sentence_idx(sentence_starts, answer_start_char_idx):\n",
    "    n_sentence = len(sentence_starts)\n",
    "    for i, sidx in enumerate(sentence_starts):\n",
    "        if i == n_sentence-1:\n",
    "            return i\n",
    "        if answer_start_char_idx >= sidx and answer_start_char_idx < sentence_starts[i+1]:\n",
    "            return i\n",
    "\n",
    "def join_slist(slist, sentence_idx, char_idx):\n",
    "    cursor = 0\n",
    "    sentence_lengths = [len(x)+1 for x in slist]\n",
    "    for i in range(sentence_idx):\n",
    "        cursor += sentence_lengths[i]\n",
    "    return ' '.join(slist), cursor+char_idx\n",
    "\n",
    "def translate_impossible(context, question, target=\"ta\", only_cache=True):\n",
    "    slist = tokenizer.tokenize(context)\n",
    "    slist_translated = ['' for _ in range(len(slist))]\n",
    "    for i, s in enumerate(slist):\n",
    "        slist_translated[i] = translate_text_use_cache(target, s, only_cache)\n",
    "    context_translated = ' '.join(slist_translated)\n",
    "    question_translated = translate_text_use_cache(target, question, only_cache)\n",
    "    return {\n",
    "            'context': context_translated,\n",
    "            'question': question_translated,\n",
    "            'answer_text': '',\n",
    "            'answer_start': -1,\n",
    "    }\n",
    "\n",
    "\n",
    "def translate_and_map(context, question, answer, answer_start_char_idx, answer_end_char_idx, target=\"ta\", verbose=False, only_cache=True):\n",
    "    slist, sentence_starts = split2sentence(context)\n",
    "    if slist is None:\n",
    "        if verbose: print('tokenized length not match')\n",
    "        return 'tokenized length not match'\n",
    "    start_char_sentence_idx = get_sentence_idx(sentence_starts, answer_start_char_idx)\n",
    "    end_char_sentence_idx = get_sentence_idx(sentence_starts, answer_end_char_idx)\n",
    "    if start_char_sentence_idx != end_char_sentence_idx:\n",
    "        if verbose: print('start and end not in same sentence')\n",
    "        return 'start and end not in same sentence'\n",
    "    sentence_containing_answer = slist[start_char_sentence_idx]\n",
    "    if sentence_containing_answer.count(answer) != 1:\n",
    "        if verbose: print('answer does not occur once in the original sentence')\n",
    "        return 'answer does not occur once in the original sentence'\n",
    "    sentence_containing_answer_translated = translate_text_use_cache(target, sentence_containing_answer, only_cache)\n",
    "    answer_translated = translate_text_use_cache(target, answer, only_cache)\n",
    "    answer_occurence = sentence_containing_answer_translated.count(answer_translated)\n",
    "    if answer_occurence != 1:\n",
    "        if verbose: print('answer does not occur once in the translated sentence')\n",
    "        return 'answer does not occur once in the translated sentence'\n",
    "    answer_insentence_idx = sentence_containing_answer_translated.find(answer_translated)\n",
    "    slist_translated = ['' for _ in range(len(slist))]\n",
    "    slist_translated[start_char_sentence_idx] = sentence_containing_answer_translated\n",
    "    for i, s in enumerate(slist):\n",
    "        if i == start_char_sentence_idx: continue\n",
    "        slist_translated[i] = translate_text_use_cache(target, s, only_cache)\n",
    "    context_translated, answer_start_char_idx_translated = join_slist(slist_translated, start_char_sentence_idx, answer_insentence_idx)\n",
    "    question_translated = translate_text_use_cache(target, question, only_cache)\n",
    "    return {\n",
    "            'context': context_translated,\n",
    "            'question': question_translated,\n",
    "            'answer_text': answer_translated,\n",
    "            'answer_start': answer_start_char_idx_translated,\n",
    "    }\n",
    "\n",
    "def estimate_price(translated_cache):\n",
    "    unit_price = 20 / 1000000\n",
    "    token_count = np.sum([len(x) for x in list(translated_cache.keys())])\n",
    "    return token_count * unit_price\n",
    "\n",
    "def read_squad(path):\n",
    "    path = Path(path)\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answer_texts = []\n",
    "    answer_starts = []\n",
    "    imp = 0\n",
    "    p = 0\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                is_impossible = qa['is_impossible']\n",
    "                question = qa['question']\n",
    "                contexts.append(context)\n",
    "                questions.append(question)\n",
    "                if is_impossible:\n",
    "                    imp += 1\n",
    "                    answer_texts.append('')\n",
    "                    answer_starts.append(-1)\n",
    "#                     answers.append({'text': '', 'answer_start': -1})\n",
    "                else:\n",
    "                    p += 1\n",
    "                    text = qa['answers'][0]['text']\n",
    "                    answer_start = qa['answers'][0]['answer_start']\n",
    "                    answer_texts.append(text)\n",
    "                    answer_starts.append(answer_start)\n",
    "#                     answers.append({'text': text, 'answer_start': answer_start})\n",
    "    print(f'imp {imp}, p {p}')\n",
    "    data = {'id': [i for i in range(len(contexts))], 'context': contexts, 'question': questions, 'answer': answer_texts, 'answer_start_char_idx': answer_starts}\n",
    "    answer_end_char_idx = []\n",
    "    for i in range(len(answer_texts)):\n",
    "        answer_end_char_idx.append(answer_starts[i]+len(answer_texts[i]))\n",
    "    data['answer_end_char_idx'] = answer_end_char_idx\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c978dec1-fd7c-4f1f-9403-4cddfaf663ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imp 43498, p 86821\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start_char_idx</th>\n",
       "      <th>answer_end_char_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>269</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>207</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "      <td>526</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>166</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130314</th>\n",
       "      <td>130314</td>\n",
       "      <td>The term \"matter\" is used throughout physics i...</td>\n",
       "      <td>Physics has broadly agreed on the definition o...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130315</th>\n",
       "      <td>130315</td>\n",
       "      <td>The term \"matter\" is used throughout physics i...</td>\n",
       "      <td>Who coined the term partonic matter?</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130316</th>\n",
       "      <td>130316</td>\n",
       "      <td>The term \"matter\" is used throughout physics i...</td>\n",
       "      <td>What is another name for anti-matter?</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130317</th>\n",
       "      <td>130317</td>\n",
       "      <td>The term \"matter\" is used throughout physics i...</td>\n",
       "      <td>Matter usually does not need to be used in con...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130318</th>\n",
       "      <td>130318</td>\n",
       "      <td>The term \"matter\" is used throughout physics i...</td>\n",
       "      <td>What field of study has a variety of unusual c...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130319 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                            context  \\\n",
       "0            0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1            1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "2            2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "3            3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "4            4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "...        ...                                                ...   \n",
       "130314  130314  The term \"matter\" is used throughout physics i...   \n",
       "130315  130315  The term \"matter\" is used throughout physics i...   \n",
       "130316  130316  The term \"matter\" is used throughout physics i...   \n",
       "130317  130317  The term \"matter\" is used throughout physics i...   \n",
       "130318  130318  The term \"matter\" is used throughout physics i...   \n",
       "\n",
       "                                                 question  \\\n",
       "0                When did Beyonce start becoming popular?   \n",
       "1       What areas did Beyonce compete in when she was...   \n",
       "2       When did Beyonce leave Destiny's Child and bec...   \n",
       "3           In what city and state did Beyonce  grow up?    \n",
       "4              In which decade did Beyonce become famous?   \n",
       "...                                                   ...   \n",
       "130314  Physics has broadly agreed on the definition o...   \n",
       "130315               Who coined the term partonic matter?   \n",
       "130316              What is another name for anti-matter?   \n",
       "130317  Matter usually does not need to be used in con...   \n",
       "130318  What field of study has a variety of unusual c...   \n",
       "\n",
       "                     answer  answer_start_char_idx  answer_end_char_idx  \n",
       "0         in the late 1990s                    269                  286  \n",
       "1       singing and dancing                    207                  226  \n",
       "2                      2003                    526                  530  \n",
       "3            Houston, Texas                    166                  180  \n",
       "4                late 1990s                    276                  286  \n",
       "...                     ...                    ...                  ...  \n",
       "130314                                          -1                   -1  \n",
       "130315                                          -1                   -1  \n",
       "130316                                          -1                   -1  \n",
       "130317                                          -1                   -1  \n",
       "130318                                          -1                   -1  \n",
       "\n",
       "[130319 rows x 6 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad2 = read_squad('../../input/squad2/train-v2.0.json')\n",
    "squad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "905dd27a-31a4-4891-b919-fc741f5218eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19029, 93697, 130217, 64764)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_contexts = squad2.context.unique()\n",
    "unique_contexts\n",
    "context_sentences = []\n",
    "for c in unique_contexts:\n",
    "    ss = tokenizer.tokenize(c)\n",
    "    context_sentences.extend(ss)\n",
    "context_sentences = list(set(context_sentences))\n",
    "unique_questions = squad2.question.unique().tolist()\n",
    "unique_answers = squad2.answer.unique().tolist()\n",
    "len(unique_contexts), len(context_sentences), len(unique_questions), len(unique_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "558ba1f6-cb0f-4df4-8be7-be6f857fdb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194768"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_translate = context_sentences + unique_questions + unique_answers\n",
    "temp = []\n",
    "for sen in to_translate:\n",
    "    if sen not in translated_cache:\n",
    "        temp.append(sen)\n",
    "to_translate = temp\n",
    "del temp\n",
    "len(to_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7a8dd62b-dae8-4cca-81c6-a74da42e0911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48d50eb3ad648e78dcc6ba9019ba59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1522 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dups = []\n",
    "bs = 128\n",
    "for i in tqdm(range(0, len(to_translate), bs)):\n",
    "    batch = to_translate[i:i+bs]\n",
    "    response = translate_texts('ta', batch)\n",
    "    for res in response:\n",
    "        if res['input'] not in translated_cache:\n",
    "            translated_cache[res['input']] = res['translatedText']\n",
    "        else:\n",
    "            dups.append(res['input'])\n",
    "            print('dup..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f069323f-3bd5-44d1-a4f7-b65b38f74082",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('squad2_en2ta_0905.json', 'w') as f:\n",
    "    json.dump(translated_cache, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8ffcb525-99ed-4bfe-ba2a-53f564121085",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2075\n",
    "context = squad2.loc[idx, 'context']\n",
    "question = squad2.loc[idx, 'question']\n",
    "answer = squad2.loc[idx, 'answer']\n",
    "answer_start_char_idx = squad2.loc[idx, 'answer_start_char_idx']\n",
    "answer_end_char_idx = squad2.loc[idx, 'answer_end_char_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fa236af5-32f4-44a3-b545-ca376bcfa60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Legend of Zelda: Twilight Princess (Japanese: ゼルダの伝説 トワイライトプリンセス, Hepburn: Zeruda no Densetsu: Towairaito Purinsesu?) is an action-adventure game developed and published by Nintendo for the GameCube and Wii home video game consoles. It is the thirteenth installment in the The Legend of Zelda series. Originally planned for release on the GameCube in November 2005, Twilight Princess was delayed by Nintendo to allow its developers to refine the game, add more content, and port it to the Wii. The Wii version was released alongside the console in North America in November 2006, and in Japan, Europe, and Australia the following month. The GameCube version was released worldwide in December 2006.[b]'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "17485a8c-0288-4aa8-a0af-d8c4361b5a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'தி லெஜண்ட் ஆஃப் செல்டா: ட்விலைட் இளவரசி (ஜப்பானிய: ゼ ル ダ の 伝 ト ワ イ ラ イ ト プ ン ン ス ス He He, ஹெப்பர்ன்: ஜெருடா நோ டென்செட்சு: டோவைரைடோ புரிஞ்சே?) கேம் கியூப் மற்றும் வீ ஹோம் வீடியோ கேம் கன்சோல்களுக்காக நிண்டெண்டோவால் உருவாக்கப்பட்டு வெளியிடப்பட்ட ஒரு அதிரடி-சாகச விளையாட்டு. இது தி லெஜண்ட் ஆஃப் செல்டா தொடரின் பதின்மூன்றாவது தவணை. முதலில் நவம்பர் 2005 இல் கேம் கியூபில் வெளியிட திட்டமிடப்பட்டது, ட்விலைட் இளவரசி நிண்டெண்டோவால் தாமதப்படுத்தப்பட்டது, அதன் டெவலப்பர்கள் விளையாட்டைச் செம்மைப்படுத்தவும், அதிக உள்ளடக்கத்தைச் சேர்க்கவும் மற்றும் வைக்கு போர்ட் செய்யவும் அனுமதித்தது. வீ பதிப்பு நவம்பர் 2006 இல் வட அமெரிக்காவில் கன்சோலுடன் வெளியிடப்பட்டது, அடுத்த மாதம் ஜப்பான், ஐரோப்பா மற்றும் ஆஸ்திரேலியாவில் வெளியிடப்பட்டது. கேம் கியூப் பதிப்பு டிசம்பர் 2006 இல் உலகளவில் வெளியிடப்பட்டது. [b]',\n",
       " 'question': 'லெஜண்ட் ஆஃப் ஜெல்டாவின் எந்த வகை விளையாட்டு: ஆஸ்திரேலியா ட்விலைட்?',\n",
       " 'answer_text': '',\n",
       " 'answer_start': -1}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res = translate_and_map(context, question, answer, answer_start_char_idx, answer_end_char_idx, target=\"ta\")\n",
    "res = translate_impossible(context, question)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "04dcbd83-8cde-48ac-b87b-b60646ebd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    max_retry = 3\n",
    "    target = 'ta'\n",
    "    err_counter = 0\n",
    "    imp_counter = 0\n",
    "    for idx in tqdm(range(len(squad2))):\n",
    "        context = squad2.loc[idx, 'context']\n",
    "        question = squad2.loc[idx, 'question']\n",
    "        answer = squad2.loc[idx, 'answer']\n",
    "        answer_start_char_idx = squad2.loc[idx, 'answer_start_char_idx']\n",
    "        answer_end_char_idx = squad2.loc[idx, 'answer_end_char_idx']\n",
    "        for i in range(max_retry):\n",
    "            try:\n",
    "                if answer_start_char_idx == -1:\n",
    "                    res = translate_impossible(context, question, only_cache=True)\n",
    "                    imp_counter += 1\n",
    "                    break\n",
    "                else:\n",
    "                    res = translate_and_map(context, question, answer, answer_start_char_idx, answer_end_char_idx, target=target, verbose=False, only_cache=True)\n",
    "                    break\n",
    "            except:\n",
    "                print(f'error encountered at step {idx}, retry counter {i}')\n",
    "                res = 'not in cache'\n",
    "                continue\n",
    "        if isinstance(res, str):\n",
    "            squad2.loc[idx, f'error_{target}'] = res\n",
    "            err_counter += 1\n",
    "        else:\n",
    "            squad2.loc[idx, f'error_{target}'] = 'success'\n",
    "            squad2.loc[idx, f'context_{target}'] = res['context']\n",
    "            squad2.loc[idx, f'question_{target}'] = res['question']\n",
    "            squad2.loc[idx, f'answer_text_{target}'] = res['answer_text']\n",
    "            squad2.loc[idx, f'answer_start_{target}'] = res['answer_start']\n",
    "        if idx % 50 == 0:\n",
    "            squad2.to_csv('squad2_translated.csv', index=False)\n",
    "            with open('translated_cache.json', 'w') as f:\n",
    "                json.dump(translated_cache, f, indent=4)\n",
    "        if idx % 1000 == 0:\n",
    "            print(idx, 'price$', int(estimate_price(translated_cache)), 'error%', int(err_counter/(idx+1)*100), 'imp%', int(imp_counter/(idx+1)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4bbd74bf-c2c6-4bf0-8ad3-01346ceba166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57dcd73333d44bce9c73ae67db6b5a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 price$ 461 error% 0 imp% 0\n",
      "1000 price$ 461 error% 56 imp% 0\n",
      "2000 price$ 461 error% 54 imp% 0\n",
      "3000 price$ 461 error% 49 imp% 11\n",
      "4000 price$ 461 error% 48 imp% 8\n",
      "5000 price$ 461 error% 49 imp% 6\n",
      "6000 price$ 461 error% 51 imp% 5\n",
      "7000 price$ 461 error% 50 imp% 4\n",
      "8000 price$ 461 error% 48 imp% 8\n",
      "9000 price$ 461 error% 46 imp% 13\n",
      "10000 price$ 461 error% 43 imp% 17\n",
      "11000 price$ 461 error% 42 imp% 20\n",
      "12000 price$ 461 error% 41 imp% 20\n",
      "13000 price$ 461 error% 40 imp% 23\n",
      "14000 price$ 461 error% 39 imp% 24\n",
      "15000 price$ 461 error% 40 imp% 24\n",
      "16000 price$ 461 error% 39 imp% 24\n",
      "17000 price$ 461 error% 39 imp% 25\n",
      "18000 price$ 461 error% 39 imp% 25\n",
      "19000 price$ 461 error% 38 imp% 26\n",
      "20000 price$ 461 error% 38 imp% 27\n",
      "21000 price$ 461 error% 38 imp% 27\n",
      "22000 price$ 461 error% 38 imp% 27\n",
      "23000 price$ 461 error% 38 imp% 27\n",
      "24000 price$ 461 error% 38 imp% 25\n",
      "25000 price$ 461 error% 39 imp% 25\n",
      "26000 price$ 461 error% 40 imp% 24\n",
      "27000 price$ 461 error% 39 imp% 25\n",
      "28000 price$ 461 error% 40 imp% 24\n",
      "29000 price$ 461 error% 40 imp% 23\n",
      "30000 price$ 461 error% 40 imp% 23\n",
      "31000 price$ 461 error% 40 imp% 23\n",
      "32000 price$ 461 error% 40 imp% 24\n",
      "33000 price$ 461 error% 40 imp% 24\n",
      "34000 price$ 461 error% 39 imp% 25\n",
      "35000 price$ 461 error% 39 imp% 26\n",
      "36000 price$ 461 error% 38 imp% 26\n",
      "37000 price$ 461 error% 38 imp% 27\n",
      "38000 price$ 461 error% 38 imp% 28\n",
      "39000 price$ 461 error% 38 imp% 28\n",
      "40000 price$ 461 error% 38 imp% 28\n",
      "41000 price$ 461 error% 38 imp% 28\n",
      "42000 price$ 461 error% 38 imp% 28\n",
      "43000 price$ 461 error% 38 imp% 28\n",
      "44000 price$ 461 error% 38 imp% 28\n",
      "45000 price$ 461 error% 38 imp% 28\n",
      "46000 price$ 461 error% 37 imp% 28\n",
      "47000 price$ 461 error% 37 imp% 29\n",
      "48000 price$ 461 error% 38 imp% 29\n",
      "49000 price$ 461 error% 37 imp% 29\n",
      "50000 price$ 461 error% 37 imp% 29\n",
      "51000 price$ 461 error% 37 imp% 29\n",
      "52000 price$ 461 error% 38 imp% 29\n",
      "53000 price$ 461 error% 37 imp% 29\n",
      "54000 price$ 461 error% 38 imp% 29\n",
      "55000 price$ 461 error% 38 imp% 29\n",
      "56000 price$ 461 error% 38 imp% 29\n",
      "57000 price$ 461 error% 38 imp% 29\n",
      "58000 price$ 461 error% 38 imp% 29\n",
      "59000 price$ 461 error% 37 imp% 29\n",
      "60000 price$ 461 error% 37 imp% 29\n",
      "61000 price$ 461 error% 37 imp% 29\n",
      "62000 price$ 461 error% 38 imp% 29\n",
      "63000 price$ 461 error% 38 imp% 29\n",
      "64000 price$ 461 error% 37 imp% 30\n",
      "65000 price$ 461 error% 37 imp% 30\n",
      "66000 price$ 461 error% 37 imp% 30\n",
      "67000 price$ 461 error% 37 imp% 30\n",
      "68000 price$ 461 error% 37 imp% 30\n",
      "69000 price$ 461 error% 37 imp% 30\n",
      "70000 price$ 461 error% 37 imp% 31\n",
      "71000 price$ 461 error% 37 imp% 31\n",
      "72000 price$ 461 error% 37 imp% 31\n",
      "73000 price$ 461 error% 37 imp% 31\n",
      "74000 price$ 461 error% 37 imp% 31\n",
      "75000 price$ 461 error% 37 imp% 31\n",
      "76000 price$ 461 error% 37 imp% 31\n",
      "77000 price$ 461 error% 37 imp% 31\n",
      "78000 price$ 461 error% 37 imp% 31\n",
      "79000 price$ 461 error% 37 imp% 31\n",
      "80000 price$ 461 error% 37 imp% 31\n",
      "81000 price$ 461 error% 37 imp% 31\n",
      "82000 price$ 461 error% 37 imp% 31\n",
      "83000 price$ 461 error% 37 imp% 32\n",
      "84000 price$ 461 error% 37 imp% 31\n",
      "85000 price$ 461 error% 37 imp% 31\n",
      "86000 price$ 461 error% 37 imp% 32\n",
      "87000 price$ 461 error% 37 imp% 32\n",
      "88000 price$ 461 error% 37 imp% 32\n",
      "89000 price$ 461 error% 37 imp% 32\n",
      "90000 price$ 461 error% 37 imp% 32\n",
      "91000 price$ 461 error% 37 imp% 32\n",
      "92000 price$ 461 error% 37 imp% 32\n",
      "93000 price$ 461 error% 37 imp% 32\n",
      "94000 price$ 461 error% 37 imp% 32\n",
      "95000 price$ 461 error% 37 imp% 32\n",
      "96000 price$ 461 error% 36 imp% 33\n",
      "97000 price$ 461 error% 36 imp% 33\n",
      "98000 price$ 461 error% 36 imp% 33\n",
      "99000 price$ 461 error% 36 imp% 33\n",
      "100000 price$ 461 error% 36 imp% 33\n",
      "101000 price$ 461 error% 36 imp% 33\n",
      "102000 price$ 461 error% 36 imp% 33\n",
      "103000 price$ 461 error% 36 imp% 33\n",
      "104000 price$ 461 error% 36 imp% 33\n",
      "105000 price$ 461 error% 36 imp% 33\n",
      "106000 price$ 461 error% 36 imp% 33\n",
      "107000 price$ 461 error% 36 imp% 33\n",
      "108000 price$ 461 error% 36 imp% 33\n",
      "109000 price$ 461 error% 36 imp% 33\n",
      "110000 price$ 461 error% 37 imp% 33\n",
      "111000 price$ 461 error% 37 imp% 33\n",
      "112000 price$ 461 error% 37 imp% 33\n",
      "113000 price$ 461 error% 37 imp% 33\n",
      "114000 price$ 461 error% 37 imp% 33\n",
      "115000 price$ 461 error% 37 imp% 33\n",
      "116000 price$ 461 error% 37 imp% 33\n",
      "117000 price$ 461 error% 36 imp% 33\n",
      "118000 price$ 461 error% 36 imp% 33\n",
      "119000 price$ 461 error% 36 imp% 33\n",
      "120000 price$ 461 error% 37 imp% 33\n",
      "121000 price$ 461 error% 37 imp% 33\n",
      "122000 price$ 461 error% 37 imp% 33\n",
      "123000 price$ 461 error% 37 imp% 33\n",
      "124000 price$ 461 error% 37 imp% 33\n",
      "125000 price$ 461 error% 37 imp% 33\n",
      "126000 price$ 461 error% 37 imp% 33\n",
      "127000 price$ 461 error% 37 imp% 33\n",
      "128000 price$ 461 error% 37 imp% 33\n",
      "129000 price$ 461 error% 37 imp% 33\n",
      "130000 price$ 461 error% 37 imp% 33\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b204f467-c39e-4051-b137-418eeb1a7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad2.to_csv('squad2_translated.csv', index=False)\n",
    "with open('translated_cache.json', 'w') as f:\n",
    "    json.dump(translated_cache, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce6fb0-759a-4892-9b70-5c8bea30a4df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3811jvsc74a57bd0e85c7858d2136923e4208c50f298eb4aa574704d2e6694f020f65d2cbc64bb5b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
